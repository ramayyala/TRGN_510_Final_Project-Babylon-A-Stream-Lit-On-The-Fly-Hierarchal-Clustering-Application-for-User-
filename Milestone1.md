# 1: Update
The Hierarchical Clustering base code is complete within the two notebooks in the notebooks named **Concatenating FPKMs** and **Clustering**. 
## Concatenating FPKMs
This notebook loads in all 446 FPKMs, and creates one large dataframe that contains a column with each ENSEMBL ID from all of the samples, and the corresponding FPKM values from each sample in the rest of the columns. SInce the samples did not have any unique names to them, I chose to name the samples from 1 to 446 in this format: **Sample_#**. After the dataframe is created, the notebook exports a csv named **FPKM_data.csv** that contains the large dataframe that will be the database for the streamlit app. This process will probably not be included in the actual app as once the database is made, there is no need to include these steps in the actual application
##  Clustering
This notebook loads in the **FPKM_data.csv** created in the previous notebook and replaces all of the ENSEMBL IDs in the first column with their HUGO ID's or their gene names using the **Homo_sapiens.GRCh37.75.gtf** as a reference, since that is the format the user will be inputting their gene sets. This HUGO ID dataframe will probably be stored by using the pickle module or python cacheing in order to increase speed of the application and remove the need to replace the ENSEMBL IDs everytime the application runs. Once this HUGO ID dataframe is made, I used a pancreatic gene set taken from [GSEA public database](https://www.gsea-msigdb.org/gsea/msigdb/genesets.jsp) to test the hieararchical clustering method. Using this gene set, I subsetted the genes from the large dataframe to a smaller dataframe.  The first test was ran using [scipy's cluster.hierarchy module](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html) to create the dendrogram to make sure the dataframe was formatted correctly. In order to create the heatmap/dendrogam, I pivoted to using [seaborn's clustermap function](https://seaborn.pydata.org/generated/seaborn.clustermap.html) as it uses scipy's clustering module to carrying out the linkage method and it outputs a clustermap with fewer lines of codes. For this project, I will be using the **ward** clustering method as that is the reccomended hierarchical clustering method with distance being calculated using **euclidean metrics**. I also added code to give an option to log scale the data which will be used as an optional parameter in the final application. 
# 2: Next Steps
The next step is to integrate this base code into streamlit's API and have an initial demo of what was demonstrated in the notebook ready. After this is done, I will add options like adding covariates, log scaling the data, and customizing colors on the heatmap for users.  
# 3: Data
The large dataframe as stated previously is stored in the data folder as **FPKM_data.csv**. All of the FPKM files for each sample are stored in the FPKMs folder within the data folder. 
# 4: Known Issues 
  1. When replacing the ENSEMBL ID's with their HUGO ID's I lose about 6,000 of the genes since those lost genes are not contained in the reference gtf **Homo_sapiens.GRCh37.75.gtf**. This isn't really an issue but more something to look into in the future to maximize the amount of genes this application can create clustermaps of. 
  2. The load time for the database is a bit slower than what I want, and will probably replaced by using the pickle module or python cache to decrease load times. 